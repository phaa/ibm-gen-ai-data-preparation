# Generative AI and LLMs: Architecture and Data Preparation – IBM

This repository contains code, notebooks, and notes developed during the [Generative AI and LLMs: Architecture and Data Preparation](https://www.coursera.org/learn/generative-ai-llm-architecture-data-preparation) course offered by **IBM** through **Coursera**.

<p align="center">
  <img src="https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png" title="IBM Skills Network" width="400" />
</p>

## About the Course

This course is part of the **Generative AI Engineering with LLMs Specialization** from IBM.  
It introduces key concepts and tools related to Generative AI architectures, tokenization, data preparation for training Large Language Models (LLMs), and working with libraries such as PyTorch and Hugging Face.

Topics include:

- Generative AI Architectures: RNNs, Transformers, GANs, VAEs, and Diffusion Models
- Language Models: GPT, BERT, BART, and T5
- Tokenization using NLTK, spaCy, BertTokenizer, and XLNetTokenizer
- Creating Data Loaders with PyTorch for NLP tasks

The course content and labs are in English; therefore, all code and documentation in this repository are maintained in the same language.

## Repository Structure

The files and notebooks are organized by course modules:
```
📁 Repository structure
├── 📁 Module 1 - Generative AI Architectures & LLMs
│ ├── 📝 Lab: Exploring GenAI libraries
├── 📁 Module 2 - Data Preparation & PyTorch Data Loaders
│ ├── 📝 Lab: Tokenizer Implementation (word, char, subword)
│ ├── 📝 Lab: Create a PyTorch NLP DataLoader
├── README.md
```

## Technologies Used
- **Python**
- **Jupyter Notebook**
- **Libraries:** PyTorch, Hugging Face Transformers, Datasets, Tokenizers, NLTK, spaCy


## How to Use  
1. Clone and access the repository:  
   ```bash
   git clone https://github.com/phaa/ibm-gen-ai-data-preparation
   cd ibm-gen-ai-data-preparation/
   ```
2. Activate the virtual environment (conda or venv):
   ```bash
   conda activate ibmenv
   ```
3. Run the notebooks in Jupyter lab:  
   ```bash
   jupyter lab
   ```
*Each notebook has a cell to install the necessary dependencies.* 

## Contributions  
This repository is a record of the course learning, but suggestions and improvements are always welcome!
